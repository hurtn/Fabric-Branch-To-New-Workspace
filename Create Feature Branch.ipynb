{"cells":[{"cell_type":"markdown","source":["##### Imports and Utility Functions\n","Ensure the cell below is runs successfully to include all the helper utilities"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dee81614-b92b-4242-890a-b11f97b1a640"},{"cell_type":"code","source":["%run workspaceutils"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"391624c1-b299-452d-9ebf-f32626d49970"},{"cell_type":"markdown","source":["###### Check default lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c5968174-5758-45ec-8c44-e3e1b7a3f42f"},{"cell_type":"code","source":["if (mssparkutils.runtime.context['defaultLakehouseId']==None):\n","    displayHTML('<div style=\"display: flex; align-items: flex-end;\"><img style=\"float: left; margin-right: 10px;\" src=\"https://github.com/hurtn/images/blob/main/stop.png?raw=true\" width=\"50\"><span><h4>Please set a default lakehouse before proceeding</span><img style=\"float: right; margin-left: 10px;\" src=\"https://github.com/hurtn/images/blob/main/stop.png?raw=true\" width=\"50\"></div>')\n","    print('\\n')\n","    raise noDefaultLakehouseException('No default lakehouse found. Please add a lakehouse to this notebook.')\n","else: \n","    print('Default lakehouse is set to '+ mssparkutils.runtime.context['defaultLakehouseName'] + '('+ mssparkutils.runtime.context['defaultLakehouseId'] + ')')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1476aa8b-a1e6-41ea-9ebc-d2ee37f8f165"},{"cell_type":"markdown","source":["##### Store metadata of Capacities, Workspaces and Items"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"db34d1b1-b30e-45d9-80f4-00ac9c77e88d"},{"cell_type":"code","source":["print(updateCp())\n","print(updateWs())\n","print(updateItems())\n","print(updateReports())"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dd025963-2232-400e-a30e-53d8e0a821ac"},{"cell_type":"markdown","source":["##### Save Workspace Git Connection Details"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c25c1e21-e58b-4d28-b748-3594cc823ce9"},{"cell_type":"code","source":["from pyspark.sql.functions import lit\n","verbose = False #flag to provide verbose error messages\n","client = fabric.FabricRestClient()\n","\n","table_name = 'gitconnections'\n","spark.sql(\"Drop table if exists \"+ table_name)\n","dfwks = spark.sql(\"SELECT distinct ID,Type,Name FROM workspaces where Type!='AdminInsights'\").collect()\n","print(\"Storing git connection details for all workspaces.\\nAny errors will appear below, some you can safely ignore such as the git connection status for the Capacity Metrics workspace...\")\n","for idx,i in enumerate(dfwks):\n","    if i['Type'] == 'Workspace':\n","        url = \"/v1/workspaces/\" + i['ID'] + \"/git/connection\"\n","        try:\n","            print(\"Storing git details for workspace \"+i['Name']+\" (\"+i['ID']+')...')\n","            response = client.get(url)\n","\n","            gitProviderDetailsJSON = response.json()['gitProviderDetails']\n","            gitConnectionStateJSON = response.json()['gitConnectionState']\n","            gitSyncDetailsJSON = response.json()['gitSyncDetails']\n","            df = spark.createDataFrame([i['ID']],\"string\").toDF(\"Workspace_ID\")\n","            df=df.withColumn(\"Workspace_Name\",lit(i['Name'])).withColumn(\"gitConnectionState\",lit(gitConnectionStateJSON)).withColumn(\"gitProviderDetails\",lit(json.dumps(gitProviderDetailsJSON))).withColumn(\"gitSyncDetails\",lit(json.dumps(gitSyncDetailsJSON)))\n","\n","            if idx == 0:\n","                dfall = df\n","            else:\n","                dfall= dfall.union(df)\n","        except Exception as error:\n","            errmsg =  \"Couldn't get git connection status for workspace \" + i['Name'] + \"(\"+ i['ID'] + \").\"\n","            if (verbose):\n","                 errmsg = errmsg + \"Error: \"+str(error)\n","            print(str(errmsg))\n","\n","dfall.withColumn(\"metaTimestamp\",current_timestamp()).write.mode('overwrite').option(\"mergeSchema\", \"true\").saveAsTable(table_name)\n","print('Done')\n","\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a8eebcaa-1262-4ecd-b914-3ea6665f9908"},{"cell_type":"code","source":["mssparkutils.runtime.context"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"03bebe97-34c4-4066-9756-99568369eec7"},{"cell_type":"code","source":["df = spark.sql(\"SELECT * FROM gitbranching.gitconnections where workspace_id = '\"+ mssparkutils.runtime.context['currentWorkspaceId'] + \"'\")\n","\n","gitsql = \"select gt.gitConnectionState,gt.gitProviderDetails, wks.name Workspace_Name, wks.id Workspace_ID from gitconnections gt \" \\\n","         \"inner join workspaces wks on gt.Workspace_Name = wks.name \" \\\n","         \"where gt.gitConnectionState = 'ConnectedAndInitialized' and wks.id = '\"+mssparkutils.runtime.context['currentWorkspaceId']+\"'\" \n","\n","dfgitdetails = spark.sql(gitsql).collect()\n","display(dfgitdetails)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"c955a238-15e0-495c-9ee3-e8ec506affc4"},{"cell_type":"code","source":["df = spark.sql(\"SELECT * FROM gitbranching.capacities LIMIT 1000\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"8fa528e8-3488-48db-a056-0a18c7acd85c"},{"cell_type":"code","source":["\n","df = spark.sql(\"SELECT capacity_id,name FROM gitbranching.workspaces where id = '\"+ mssparkutils.runtime.context['currentWorkspaceId'] + \"'\").collect()\n","current_capacity_id = df[0][0]\n","current_ws_name = df[0][1]\n","print('Current capacity ID = '+current_capacity_id + ' for workspace ' + current_ws_name)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"b6481ecc-5c7f-46a6-8c5a-414458651c6c"},{"cell_type":"code","source":["branch_to_new_ws = 'DEV_Custom_Feature_02'\n","branch_name = 'DEV_Custom_Feature_02_branch'\n","try:\n","    print(\"Creating workspace: \" + branch_to_new_ws + \" in capacity \"+ current_capacity_id +\"...\")\n","    response = fabric.create_workspace(branch_to_new_ws,current_capacity_id) \n","    new_workspace_id = response\n","    print(\"Created workspace with ID: \" + new_workspace_id)\n","except Exception as error:\n","    errmsg =  \"Failed to recreate workspace \" +branch_to_new_ws + \" with capacity ID (\"+ current_capacity_id + \") due to: \"+str(error)\n","    print(errmsg)\n","\n","# Now update workspace table\n","updateWs()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d643c26f-929f-4801-aebc-1fdfe86f2c73"},{"cell_type":"code","source":["df = spark.sql(\"SELECT * FROM gitbranching.workspaces where name = '\"+ branch_to_new_ws + \"'\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"d2a42ca6-df0f-44e7-baed-429662fcd0da"},{"cell_type":"code","source":["gitpayloadstr= '{\"gitProviderDetails\": ' + dfgitdetails[0][1] + '}'\n","print(\"Before: \" + gitpayloadstr)\n","gitpayload = json.loads(gitpayloadstr)\n","gitpayload[\"gitProviderDetails\"][\"branchName\"] = branch_name\n","print(\"After: \" +json.dumps(gitpayload))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6bc035a3-3611-4440-9a99-a1b27b171600"},{"cell_type":"code","source":["url = \"/v1/workspaces/\" +  new_workspace_id + \"/git/connect\"\n","\n","try:\n","    print('Attempting to connect workspace '+ branch_to_new_ws)\n","    response = client.post(url,json= gitpayload)\n","    print(str(response.status_code) + response.text) \n","    success = True\n","    \n","except Exception as error:\n","    errmsg =  \"Couldn't connect git to workspace \" + branch_to_new_ws + \". Error: \"+str(error)\n","    print(str(errmsg))\n","    success = False\n","# If connection successful then try to initialise    \n","if (success):\n","    url = \"/v1/workspaces/\" + new_workspace_id + \"/git//initializeConnection\"\n","    payload = {\"initializationStrategy\":\"PreferRemote\"}\n","    try:\n","        print('Attempting to initialize git connection for workspace '+ branch_to_new_ws)\n","        response = client.post(url,json= payload)\n","        #print(str(response.status_code) + response.text) \n","        commithash = response.json()['remoteCommitHash']\n","        print('Successfully initialized. Updating with commithash '+commithash)\n","        if commithash!='':\n","            url = \"/v1/workspaces/\" + new_workspace_id + \"/git/updateFromGit\"\n","            payload = '{\"remoteCommitHash\": \"' + commithash + '\",\"conflictResolution\": {\"conflictResolutionType\": \"Workspace\",\"conflictResolutionPolicy\": \"PreferWorkspace\"},\"options\": {\"allowOverrideItems\": true}}'\n","            response = client.post(url,json= json.loads(payload))\n","            print(str(response.status_code))\n","    except Exception as error:\n","        errmsg =  \"Couldn't initialize git for workspace \" +branch_to_new_ws + \". Error: \"+str(error)\n","        print(str(errmsg))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8704cc7c-30bd-4296-b5eb-d27e6f8c8d59"},{"cell_type":"code","source":["df = spark.sql(\"SELECT * FROM gitbranching.workspaces LIMIT 1000\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"91fe6bcf-c4da-48ac-9975-d895996210cc"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}